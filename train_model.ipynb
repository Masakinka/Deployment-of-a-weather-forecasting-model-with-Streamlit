{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wtvvcAu1YGwZ"
      },
      "id": "wtvvcAu1YGwZ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8swPXYnnZuly",
        "outputId": "66140b0e-9d87-4ec2-f5b5-9dae5f368413"
      },
      "id": "8swPXYnnZuly",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = pd.read_csv(\"drive/MyDrive/Colab Notebooks/data/weatherAUS.csv\")\n",
        "data = pd.read_csv(\"/data/weatherAUS.csv\")"
      ],
      "metadata": {
        "id": "eDTdAcK1lcAs"
      },
      "id": "eDTdAcK1lcAs",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Prepare the data\n",
        "# Selecting the required columns\n",
        "selected_columns = [\n",
        "    'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
        "    'Cloud3pm', 'Temp9am', 'Temp3pm', 'RainToday', 'RainTomorrow'\n",
        "]\n",
        "data = data[selected_columns]\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data['RainTomorrow'] = label_encoder.fit_transform(data['RainTomorrow'])\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.drop(columns='RainTomorrow')\n",
        "y = data['RainTomorrow']\n",
        "\n",
        "# Train-test split\n",
        "# Split the data into training and testing sets\n",
        "seed = 42  # Set random seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=seed, stratify=y)\n",
        "\n",
        "# Step 2: Build the pipeline\n",
        "# Define preprocessing for numerical features: impute missing values, scale features\n",
        "numerical_features = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Define preprocessing for categorical features: impute missing values, encode as binary\n",
        "categorical_features = ['RainToday']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(drop='if_binary'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create the full pipeline by adding the classifier\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "HmH_4tkfnGbS"
      },
      "id": "HmH_4tkfnGbS",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Train and evaluate the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the Random Forest model with pipeline: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLT2FN0znm6G",
        "outputId": "9f78190d-0a9b-43db-8232-d68a6070c12f"
      },
      "id": "zLT2FN0znm6G",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Random Forest model with pipeline: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the pipeline model with compression\n",
        "#joblib.dump(pipeline, 'drive/MyDrive/Colab Notebooks/models/aussie_rain_pipeline.joblib', compress=('zlib', 3))\n",
        "joblib.dump(pipeline, '/models/aussie_rain_pipeline.joblib', compress=('zlib', 3))"
      ],
      "metadata": {
        "id": "uOuNFXKfZL4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a853faa4-0a15-4ec5-9f68-0e77dded2c10"
      },
      "id": "uOuNFXKfZL4Z",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/MyDrive/Colab Notebooks/models/aussie_rain_pipeline.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "documented-disney"
      ],
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}